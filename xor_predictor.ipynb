{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-24T09:45:53.684521800Z",
     "start_time": "2025-02-24T09:45:53.551252400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "#读入模型\n",
    "from lib.model.XORModel import xorModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs=50, lr=0.01):\n",
    "    # criterion = nn.MSELoss()  # 推荐的损失函数\n",
    "    criterion = nn.BCELoss()  # 推荐的损失函数\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            #将inputs和targets变成\n",
    "            inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch_loss /= len(train_loader)\n",
    "        print(f\"[train] Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss:.7f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs.squeeze(), targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            print(f\"[val] Epoch {epoch + 1}/{epochs}, Loss: {val_loss:.7f}\")\n",
    "\n",
    "    print(\"Finished Training\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-24T09:46:59.046122600Z",
     "start_time": "2025-02-24T09:45:53.681169300Z"
    }
   },
   "id": "6b69a3cf81b2d571"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Epoch 1/100, Loss: 0.4334556\n",
      "[val] Epoch 1/100, Loss: 0.1486947\n",
      "[train] Epoch 2/100, Loss: 0.0980067\n",
      "[val] Epoch 2/100, Loss: 0.0877682\n",
      "[train] Epoch 3/100, Loss: 0.0814526\n",
      "[val] Epoch 3/100, Loss: 0.0482834\n",
      "[train] Epoch 4/100, Loss: 0.0447657\n",
      "[val] Epoch 4/100, Loss: 0.0443489\n",
      "[train] Epoch 5/100, Loss: 0.0441016\n",
      "[val] Epoch 5/100, Loss: 0.0438200\n",
      "[train] Epoch 6/100, Loss: 0.0439043\n",
      "[val] Epoch 6/100, Loss: 0.0421617\n",
      "[train] Epoch 7/100, Loss: 0.0453441\n",
      "[val] Epoch 7/100, Loss: 0.0129167\n",
      "[train] Epoch 8/100, Loss: 0.0013959\n",
      "[val] Epoch 8/100, Loss: 0.0001086\n",
      "[train] Epoch 9/100, Loss: 0.0000804\n",
      "[val] Epoch 9/100, Loss: 0.0000629\n",
      "[train] Epoch 10/100, Loss: 0.0000532\n",
      "[val] Epoch 10/100, Loss: 0.0000460\n",
      "[train] Epoch 11/100, Loss: 0.0000402\n",
      "[val] Epoch 11/100, Loss: 0.0000363\n",
      "[train] Epoch 12/100, Loss: 0.0000323\n",
      "[val] Epoch 12/100, Loss: 0.0000295\n",
      "[train] Epoch 13/100, Loss: 0.0000267\n",
      "[val] Epoch 13/100, Loss: 0.0000247\n",
      "[train] Epoch 14/100, Loss: 0.0000225\n",
      "[val] Epoch 14/100, Loss: 0.0000211\n",
      "[train] Epoch 15/100, Loss: 0.0000193\n",
      "[val] Epoch 15/100, Loss: 0.0000181\n",
      "[train] Epoch 16/100, Loss: 0.0000167\n",
      "[val] Epoch 16/100, Loss: 0.0000158\n",
      "[train] Epoch 17/100, Loss: 0.0000147\n",
      "[val] Epoch 17/100, Loss: 0.0000139\n",
      "[train] Epoch 18/100, Loss: 0.0000128\n",
      "[val] Epoch 18/100, Loss: 0.0000122\n",
      "[train] Epoch 19/100, Loss: 0.0000114\n",
      "[val] Epoch 19/100, Loss: 0.0000108\n",
      "[train] Epoch 20/100, Loss: 0.0000101\n",
      "[val] Epoch 20/100, Loss: 0.0000097\n",
      "[train] Epoch 21/100, Loss: 0.0000090\n",
      "[val] Epoch 21/100, Loss: 0.0000086\n",
      "[train] Epoch 22/100, Loss: 0.0000081\n",
      "[val] Epoch 22/100, Loss: 0.0000077\n",
      "[train] Epoch 23/100, Loss: 0.0000073\n",
      "[val] Epoch 23/100, Loss: 0.0000070\n",
      "[train] Epoch 24/100, Loss: 0.0000066\n",
      "[val] Epoch 24/100, Loss: 0.0000063\n",
      "[train] Epoch 25/100, Loss: 0.0000059\n",
      "[val] Epoch 25/100, Loss: 0.0000057\n",
      "[train] Epoch 26/100, Loss: 0.0000054\n",
      "[val] Epoch 26/100, Loss: 0.0000051\n",
      "[train] Epoch 27/100, Loss: 0.0000049\n",
      "[val] Epoch 27/100, Loss: 0.0000047\n",
      "[train] Epoch 28/100, Loss: 0.0000044\n",
      "[val] Epoch 28/100, Loss: 0.0000042\n",
      "[train] Epoch 29/100, Loss: 0.0000040\n",
      "[val] Epoch 29/100, Loss: 0.0000038\n",
      "[train] Epoch 30/100, Loss: 0.0000037\n",
      "[val] Epoch 30/100, Loss: 0.0000035\n",
      "[train] Epoch 31/100, Loss: 0.0000033\n",
      "[val] Epoch 31/100, Loss: 0.0000032\n",
      "[train] Epoch 32/100, Loss: 0.0000030\n",
      "[val] Epoch 32/100, Loss: 0.0000029\n",
      "[train] Epoch 33/100, Loss: 0.0000028\n",
      "[val] Epoch 33/100, Loss: 0.0000027\n",
      "[train] Epoch 34/100, Loss: 0.0000025\n",
      "[val] Epoch 34/100, Loss: 0.0000024\n",
      "[train] Epoch 35/100, Loss: 0.0000023\n",
      "[val] Epoch 35/100, Loss: 0.0000022\n",
      "[train] Epoch 36/100, Loss: 0.0000021\n",
      "[val] Epoch 36/100, Loss: 0.0000020\n",
      "[train] Epoch 37/100, Loss: 0.0000019\n",
      "[val] Epoch 37/100, Loss: 0.0000019\n",
      "[train] Epoch 38/100, Loss: 0.0000018\n",
      "[val] Epoch 38/100, Loss: 0.0000017\n",
      "[train] Epoch 39/100, Loss: 0.0000016\n",
      "[val] Epoch 39/100, Loss: 0.0000016\n",
      "[train] Epoch 40/100, Loss: 0.0000015\n",
      "[val] Epoch 40/100, Loss: 0.0000014\n",
      "[train] Epoch 41/100, Loss: 0.0000014\n",
      "[val] Epoch 41/100, Loss: 0.0000013\n",
      "[train] Epoch 42/100, Loss: 0.0000013\n",
      "[val] Epoch 42/100, Loss: 0.0000012\n",
      "[train] Epoch 43/100, Loss: 0.0000011\n",
      "[val] Epoch 43/100, Loss: 0.0000011\n",
      "[train] Epoch 44/100, Loss: 0.0000011\n",
      "[val] Epoch 44/100, Loss: 0.0000010\n",
      "[train] Epoch 45/100, Loss: 0.0000010\n",
      "[val] Epoch 45/100, Loss: 0.0000009\n",
      "[train] Epoch 46/100, Loss: 0.0000009\n",
      "[val] Epoch 46/100, Loss: 0.0000009\n",
      "[train] Epoch 47/100, Loss: 0.0000008\n",
      "[val] Epoch 47/100, Loss: 0.0000008\n",
      "[train] Epoch 48/100, Loss: 0.0000007\n",
      "[val] Epoch 48/100, Loss: 0.0000007\n",
      "[train] Epoch 49/100, Loss: 0.0000007\n",
      "[val] Epoch 49/100, Loss: 0.0000007\n",
      "[train] Epoch 50/100, Loss: 0.0000006\n",
      "[val] Epoch 50/100, Loss: 0.0000006\n",
      "[train] Epoch 51/100, Loss: 0.0000006\n",
      "[val] Epoch 51/100, Loss: 0.0000006\n",
      "[train] Epoch 52/100, Loss: 0.0000005\n",
      "[val] Epoch 52/100, Loss: 0.0000005\n",
      "[train] Epoch 53/100, Loss: 0.0000005\n",
      "[val] Epoch 53/100, Loss: 0.0000005\n",
      "[train] Epoch 54/100, Loss: 0.0000005\n",
      "[val] Epoch 54/100, Loss: 0.0000004\n",
      "[train] Epoch 55/100, Loss: 0.0000004\n",
      "[val] Epoch 55/100, Loss: 0.0000004\n",
      "[train] Epoch 56/100, Loss: 0.0000004\n",
      "[val] Epoch 56/100, Loss: 0.0000004\n",
      "[train] Epoch 57/100, Loss: 0.0000004\n",
      "[val] Epoch 57/100, Loss: 0.0000003\n",
      "[train] Epoch 58/100, Loss: 0.0000003\n",
      "[val] Epoch 58/100, Loss: 0.0000003\n",
      "[train] Epoch 59/100, Loss: 0.0000003\n",
      "[val] Epoch 59/100, Loss: 0.0000003\n",
      "[train] Epoch 60/100, Loss: 0.0000003\n",
      "[val] Epoch 60/100, Loss: 0.0000003\n",
      "[train] Epoch 61/100, Loss: 0.0000003\n",
      "[val] Epoch 61/100, Loss: 0.0000002\n",
      "[train] Epoch 62/100, Loss: 0.0000002\n",
      "[val] Epoch 62/100, Loss: 0.0000002\n",
      "[train] Epoch 63/100, Loss: 0.0000002\n",
      "[val] Epoch 63/100, Loss: 0.0000002\n",
      "[train] Epoch 64/100, Loss: 0.0000002\n",
      "[val] Epoch 64/100, Loss: 0.0000002\n",
      "[train] Epoch 65/100, Loss: 0.0000002\n",
      "[val] Epoch 65/100, Loss: 0.0000002\n",
      "[train] Epoch 66/100, Loss: 0.0000002\n",
      "[val] Epoch 66/100, Loss: 0.0000002\n",
      "[train] Epoch 67/100, Loss: 0.0000002\n",
      "[val] Epoch 67/100, Loss: 0.0000001\n",
      "[train] Epoch 68/100, Loss: 0.0000001\n",
      "[val] Epoch 68/100, Loss: 0.0000001\n",
      "[train] Epoch 69/100, Loss: 0.0000001\n",
      "[val] Epoch 69/100, Loss: 0.0000001\n",
      "[train] Epoch 70/100, Loss: 0.0000001\n",
      "[val] Epoch 70/100, Loss: 0.0000001\n",
      "[train] Epoch 71/100, Loss: 0.0000001\n",
      "[val] Epoch 71/100, Loss: 0.0000001\n",
      "[train] Epoch 72/100, Loss: 0.0000001\n",
      "[val] Epoch 72/100, Loss: 0.0000001\n",
      "[train] Epoch 73/100, Loss: 0.0000001\n",
      "[val] Epoch 73/100, Loss: 0.0000001\n",
      "[train] Epoch 74/100, Loss: 0.0000001\n",
      "[val] Epoch 74/100, Loss: 0.0000001\n",
      "[train] Epoch 75/100, Loss: 0.0000001\n",
      "[val] Epoch 75/100, Loss: 0.0000001\n",
      "[train] Epoch 76/100, Loss: 0.0000001\n",
      "[val] Epoch 76/100, Loss: 0.0000001\n",
      "[train] Epoch 77/100, Loss: 0.0000001\n",
      "[val] Epoch 77/100, Loss: 0.0000001\n",
      "[train] Epoch 78/100, Loss: 0.0000001\n",
      "[val] Epoch 78/100, Loss: 0.0000001\n",
      "[train] Epoch 79/100, Loss: 0.0000001\n",
      "[val] Epoch 79/100, Loss: 0.0000001\n",
      "[train] Epoch 80/100, Loss: 0.0000001\n",
      "[val] Epoch 80/100, Loss: 0.0000000\n",
      "[train] Epoch 81/100, Loss: 0.0000000\n",
      "[val] Epoch 81/100, Loss: 0.0000000\n",
      "[train] Epoch 82/100, Loss: 0.0000000\n",
      "[val] Epoch 82/100, Loss: 0.0000000\n",
      "[train] Epoch 83/100, Loss: 0.0000000\n",
      "[val] Epoch 83/100, Loss: 0.0000000\n",
      "[train] Epoch 84/100, Loss: 0.0000000\n",
      "[val] Epoch 84/100, Loss: 0.0000000\n",
      "[train] Epoch 85/100, Loss: 0.0000000\n",
      "[val] Epoch 85/100, Loss: 0.0000000\n",
      "[train] Epoch 86/100, Loss: 0.0000000\n",
      "[val] Epoch 86/100, Loss: 0.0000000\n",
      "[train] Epoch 87/100, Loss: 0.0000000\n",
      "[val] Epoch 87/100, Loss: 0.0000000\n",
      "[train] Epoch 88/100, Loss: 0.0000000\n",
      "[val] Epoch 88/100, Loss: 0.0000000\n",
      "[train] Epoch 89/100, Loss: 0.0000000\n",
      "[val] Epoch 89/100, Loss: 0.0000000\n",
      "[train] Epoch 90/100, Loss: 0.0000000\n",
      "[val] Epoch 90/100, Loss: 0.0000000\n",
      "[train] Epoch 91/100, Loss: 0.0000000\n",
      "[val] Epoch 91/100, Loss: 0.0000000\n",
      "[train] Epoch 92/100, Loss: 0.0000000\n",
      "[val] Epoch 92/100, Loss: 0.0000000\n",
      "[train] Epoch 93/100, Loss: 0.0000000\n",
      "[val] Epoch 93/100, Loss: 0.0000000\n",
      "[train] Epoch 94/100, Loss: 0.0000000\n",
      "[val] Epoch 94/100, Loss: 0.0000000\n",
      "[train] Epoch 95/100, Loss: 0.0000000\n",
      "[val] Epoch 95/100, Loss: 0.0000000\n",
      "[train] Epoch 96/100, Loss: 0.0000000\n",
      "[val] Epoch 96/100, Loss: 0.0000000\n",
      "[train] Epoch 97/100, Loss: 0.0000000\n",
      "[val] Epoch 97/100, Loss: 0.0000000\n",
      "[train] Epoch 98/100, Loss: 0.0000000\n",
      "[val] Epoch 98/100, Loss: 0.0000000\n",
      "[train] Epoch 99/100, Loss: 0.0000000\n",
      "[val] Epoch 99/100, Loss: 0.0000000\n",
      "[train] Epoch 100/100, Loss: 0.0000000\n",
      "[val] Epoch 100/100, Loss: 0.0000000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from lib.dataset.xor import xor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = xor('train')\n",
    "val_data = xor('val')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=256, shuffle=False)\n",
    "\n",
    "model = xorModel()\n",
    "model.to(device)\n",
    "\n",
    "train_model(model, train_loader, val_loader, epochs=100, lr=0.01)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-24T09:46:59.046122600Z",
     "start_time": "2025-02-24T09:45:53.817278700Z"
    }
   },
   "id": "ab9096bc6a632ca4"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0000 %\n"
     ]
    }
   ],
   "source": [
    "# 测试模型\n",
    "test_data = xor('test')\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device).float(), targets.to(device).float()\n",
    "        outputs = model(inputs)\n",
    "        predicted = (outputs > 0.5).float()\n",
    "        \n",
    "        correct_bits = (predicted == targets)\n",
    "        correct_samples = correct_bits.all(dim=1).sum().item()  # 按列检查是否所有位都正确\n",
    "        correct += correct_samples\n",
    "        total += targets.size(0)\n",
    "        \n",
    "        # print(f\"Predicted: {predicted}, Ground Truth: {targets}\")\n",
    "\n",
    "print(f\"Accuracy: {correct / total * 100:.4f} %\")\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-24T09:46:59.344665900Z",
     "start_time": "2025-02-24T09:46:59.048074300Z"
    }
   },
   "id": "1b83484ddf0898d0"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"xor_model.pth\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-02-24T09:46:59.473873100Z",
     "start_time": "2025-02-24T09:46:59.344665900Z"
    }
   },
   "id": "d6a06781a858b69c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
